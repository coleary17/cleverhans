\n# System Patterns\n\n## Architecture Overview\n\n### High-Level Design\n```\n┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n│   Audio Input   │───▶│  Stage 1 Attack  │───▶│ Stage 2 Masking │\n│  (LibriSpeech)  │    │   (Optimization)  │    │  (Imperceptible) │\n└─────────────────┘    └──────────────────┘    └─────────────────┘\n         │                        │                        │\n         ▼                        ▼                        ▼\n┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n│ Target Text     │    │ Loss Computation │    │ Adversarial     │\n│ (Attack Goal)   │    │ (Whisper Model)  │    │ Audio Output    │\n└─────────────────┘    └──────────────────┘    └─────────────────┘\n```\n\n### Component Architecture\n\n#### 1. **Audio Processing Layer** (`audio_utils.py`)\n- **WhisperASRModel**: Wrapper around Hugging Face Whisper\n- **Feature Extraction**: Audio → Spectrogram conversion\n- **Device Management**: CPU/GPU abstraction\n- **Batch Processing**: Multiple audio files simultaneously\n\n#### 2. **Psychoacoustic Layer** (`masking_threshold.py`)\n- **Masking Threshold Computation**: Frequency-domain perceptual limits\n- **PSD Analysis**: Power spectral density calculations\n- **Transform Operations**: FFT/IFFT for frequency domain work\n\n#### 3. **Attack Orchestration** (`adversarial_attack.py`)\n- **Two-Stage Framework**: Separate effectiveness and imperceptibility optimization\n- **Gradient-Based Optimization**: Adam optimizer for perturbation search\n- **Batch Management**: Process 1-5 audio samples per batch\n- **Results Tracking**: Loss monitoring and convergence detection\n\n## Key Technical Decisions\n\n### 1. **Model Selection: OpenAI Whisper**\n**Decision**: Use Whisper instead of original lingvo model\n**Rationale**: \n- Widely adopted in modern applications\n- Easy installation via Hugging Face transformers\n- Better maintained than legacy Google lingvo\n- More representative of current ASR landscape\n\n**Trade-offs**:\n- ✅ Modern, well-supported, widely used\n- ❌ Different architecture creates gradient flow challenges\n- ❌ Preprocessing pipeline not designed for adversarial attacks\n\n### 2. **Framework: PyTorch over TensorFlow**\n**Decision**: Complete migration from TensorFlow 1.x to PyTorch\n**Rationale**:\n- TensorFlow 1.x deprecated and unsupported\n- PyTorch more intuitive for research and debugging\n- Better integration with Hugging Face ecosystem\n- Cleaner computational graph management\n\n**Implementation**:\n- Manual tensor management instead of TF sessions\n- Adam optimizer replaces TF optimizers\n- Custom loss functions instead of TF ops\n\n### 3. **Containerization Strategy**\n**Decision**: Docker-first deployment with multi-architecture support\n**Rationale**:\n- Eliminates dependency installation issues\n- Ensures reproducible execution environment\n- Supports both development (ARM64 Mac) and production (x86_64 Linux)\n\n**Pattern**:\n```dockerfile\nFROM python:3.11-slim AS base\n# Multi-stage build for ARM64/x86_64 compatibility\n# UV package manager for fast, reproducible builds\n# Automatic device detection at runtime\n```\n\n## Design Patterns in Use\n\n### 1. **Strategy Pattern** - Device Management\n```python\nclass WhisperASRModel:\n    def __init__(self, device='cpu'):\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        # Automatic fallback strategy\n```\n\n### 2. **Template Method** - Attack Framework\n```python\nclass AdversarialAttack:\n    def run_attack(self):  # Template method\n        batch = self.prepare_batch()     # Step 1\n        stage1 = self.stage1_attack()    # Step 2\n        stage2 = self.stage2_attack()    # Step 3 (future)\n```\n\n### 3. **Facade Pattern** - Audio Processing\n```python\n# Complex librosa/whisper operations hidden behind simple interface\ndef load_audio_file(filepath, target_sr=16000):\n    # Handles resampling, normalization, format conversion\n    return audio, sr\n```\n\n### 4. **Factory Pattern** - Feature Creation\n```python\ndef create_features(audio_batch, sample_rate=16000):\n    # Creates appropriate features for different models\n    # Abstracts Whisper-specific preprocessing\n```\n\n## Component Relationships\n\n### Data Flow Patterns\n1. **Audio Loading**: `load_audio_file()` → numpy arrays\n2. **Tensor Conversion**: numpy → PyTorch tensors with gradients\n3. **Feature Extraction**: Raw audio → Whisper-compatible spectrograms\n4. **Loss Computation**: Features + target text → differentiable loss\n5. **Optimization**: Loss gradients → audio perturbations\n6. **Output Generation**: Modified tensors → audio files\n\n### Dependency Graph\n```\nadversarial_attack.py (orchestration)\n    ├── audio_utils.py (Whisper integration)\n    │   ├── transformers.WhisperProcessor\n    │   ├── transformers.WhisperForConditionalGeneration\n    │   └── librosa (audio processing)\n    ├── masking_threshold.py (psychoacoustics)\n    │   ├── numpy.fft (frequency domain)\n    │   └── scipy.signal (filtering)\n    └── torch (optimization framework)\n```\n\n## Critical Implementation Paths\n\n### 1. **Gradient Flow Path** (Currently Broken)\n```python\naudio_tensor (requires_grad=True)\n    ↓\nWhisperProcessor.__call__()  # ❌ Breaks gradients\n    ↓\nmodel.forward()\n    ↓\nloss.backward()  # ❌ No gradients reach audio_tensor\n```\n\n### 2. **Working Transcription Path**\n```python\naudio_numpy\n    ↓\nWhisperProcessor.__call__()  # ✅ Works fine\n    ↓\nmodel.generate()\n    ↓\ntranscription_tex
